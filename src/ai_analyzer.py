#!/usr/bin/env python3
"""
AI Analyzer ëª¨ë“ˆ - í¼í”Œë ‰ì‹œí‹° APIë¥¼ ì‚¬ìš©í•œ ì—ëŸ¬ ë¶„ì„ ë° í•´ê²°ì±… ìƒì„±
"""

import yaml
import json
import logging
import hashlib
from typing import Dict, List, Optional, Any
from openai import OpenAI
from .database import DatabaseManager

class AIAnalyzer:
    """í¼í”Œë ‰ì‹œí‹° AIë¥¼ ì‚¬ìš©í•œ ì—ëŸ¬ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = None):
        """
        AI ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.config = self._load_config(config_path)
        self.db = DatabaseManager(config_path)
        self.logger = logging.getLogger(__name__)
        
        # í¼í”Œë ‰ì‹œí‹° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (OpenAI í˜¸í™˜)
        perplexity_config = self.config['perplexity']
        self.client = OpenAI(
            api_key=perplexity_config['api_key'],
            base_url=perplexity_config['base_url']
        )
        self.model = perplexity_config['model']
        
    def _load_config(self, config_path: str) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ (í™˜ê²½ ë³€ìˆ˜ í¬í•¨)"""
        try:
            from .load_env import load_config_with_env
            return load_config_with_env(config_path)
        except Exception as e:
            raise Exception(f"ì„¤ì • íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    
    def analyze_error(self, error_data: Dict) -> Optional[Dict]:
        """
        ë‹¨ì¼ ì—ëŸ¬ ë¶„ì„
        
        Args:
            error_data: ì—ëŸ¬ ì •ë³´
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë° í•´ê²°ì±…
        """
        try:
            # ê¸°ì¡´ í•´ê²°ì±…ì´ ìˆëŠ”ì§€ í™•ì¸
            error_hash = self.db.create_hash_signature(
                error_data['error_type'], 
                error_data['error_message']
            )
            
            if self.db.connect():
                existing_solution = self.db.get_solution_by_error_hash(error_hash)
                if existing_solution and existing_solution['success_rate'] > 50:
                    self.logger.info(f"ğŸ“š ê¸°ì¡´ í•´ê²°ì±… ë°œê²¬ (ì„±ê³µë¥ : {existing_solution['success_rate']}%) - AI ë¶„ì„ ì—†ì´ DBì—ì„œ ì¬ì‚¬ìš©")
                    # ê¸°ì¡´ í•´ê²°ì±… ì¬ì‚¬ìš© í‘œì‹œ
                    existing_solution['is_reused'] = True
                    existing_solution['reuse_source'] = 'database'
                    return existing_solution
            
            # AI ë¶„ì„ ìš”ì²­
            analysis_result = self._request_ai_analysis(error_data)
            
            if analysis_result:
                # í•´ê²°ì±…ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                solution_data = {
                    'error_hash': error_hash,
                    'solution_type': analysis_result['solution_type'],
                    'solution_description': analysis_result['description'],
                    'solution_commands': analysis_result['commands'],
                    'ai_analysis': analysis_result['analysis']
                }
                
                solution_id = self.db.insert_solution(solution_data)
                if solution_id:
                    analysis_result['solution_id'] = solution_id
                    self.logger.info(f"ğŸ¤– ìƒˆë¡œìš´ í•´ê²°ì±… ì €ì¥ë¨: ID={solution_id} - AI ë¶„ì„ ê²°ê³¼")
                
                # ìƒˆë¡œìš´ AI ë¶„ì„ ê²°ê³¼ í‘œì‹œ
                analysis_result['is_reused'] = False
                analysis_result['reuse_source'] = 'ai_analysis'
                
                return analysis_result
            
            return None
            
        except Exception as e:
            self.logger.error(f"ì—ëŸ¬ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
        finally:
            self.db.disconnect()
    
    def _request_ai_analysis(self, error_data: Dict) -> Optional[Dict]:
        """
        í¼í”Œë ‰ì‹œí‹° AIì— ì—ëŸ¬ ë¶„ì„ ìš”ì²­
        
        Args:
            error_data: ì—ëŸ¬ ì •ë³´
            
        Returns:
            AI ë¶„ì„ ê²°ê³¼
        """
        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_analysis_prompt(error_data)
            
            # í¼í”Œë ‰ì‹œí‹° API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ Kubernetesì™€ ELK Stack ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì—ëŸ¬ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ í•´ê²°ì±…ì„ JSON í˜•íƒœë¡œ ì œê³µí•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                temperature=0.1,
                max_tokens=2000
            )
            
            # ì‘ë‹µ íŒŒì‹±
            ai_response = response.choices[0].message.content
            self.logger.info("AI ë¶„ì„ ì™„ë£Œ")
            
            # JSON ì‘ë‹µ íŒŒì‹±
            return self._parse_ai_response(ai_response, error_data)
            
        except Exception as e:
            self.logger.error(f"AI ë¶„ì„ ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None
    
    def _build_analysis_prompt(self, error_data: Dict) -> str:
        """
        AI ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        
        Args:
            error_data: ì—ëŸ¬ ì •ë³´
            
        Returns:
            êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸
        """
        prompt = f"""
ë‹¤ìŒ ì—ëŸ¬ë¥¼ ë¶„ì„í•˜ê³  í•´ê²°ì±…ì„ ì œê³µí•´ì£¼ì„¸ìš”:

## ì—ëŸ¬ ì •ë³´
- **ì—ëŸ¬ íƒ€ì…**: {error_data['error_type']}
- **ì—ëŸ¬ ë©”ì‹œì§€**: {error_data['error_message']}
- **ì†ŒìŠ¤ ì‹œìŠ¤í…œ**: {error_data['source_system']}
- **ì‹¬ê°ë„**: {error_data['severity']}

## ì¶”ê°€ ì •ë³´
"""
        
        if error_data.get('stack_trace'):
            prompt += f"- **ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤**: {error_data['stack_trace'][:500]}...\n"
        
        if error_data.get('raw_log_data'):
            raw_data = error_data['raw_log_data']
            if isinstance(raw_data, dict):
                prompt += f"- **ì›ì‹œ ë¡œê·¸**: {json.dumps(raw_data, indent=2)[:1000]}...\n"
        
        prompt += """

## ìš”ì²­ì‚¬í•­
ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

```json
{
    "analysis": "ì—ëŸ¬ì˜ ì›ì¸ê³¼ ìƒí™©ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„",
    "solution_type": "kubernetes|config_fix|restart|scaling|network|storage",
    "description": "í•´ê²°ì±…ì— ëŒ€í•œ ì„¤ëª…",
    "commands": [
        {
            "type": "kubectl|bash|config",
            "command": "ì‹¤í–‰í•  ëª…ë ¹ì–´",
            "description": "ëª…ë ¹ì–´ ì„¤ëª…",
            "safe": true|false
        }
    ],
    "priority": "high|medium|low",
    "estimated_time": "ì˜ˆìƒ í•´ê²° ì‹œê°„ (ë¶„)",
    "success_probability": "ì„±ê³µ í™•ë¥  (0-100)"
}
```

## ì¤‘ìš”ì‚¬í•­
1. Kubernetes í™˜ê²½ (ë„¤ì„ìŠ¤í˜ì´ìŠ¤: elk-stack)
2. ELK Stack ì»´í¬ë„ŒíŠ¸ (Elasticsearch, Logstash, Kibana, Filebeat)
3. ì•ˆì „í•œ ëª…ë ¹ì–´ë§Œ ì œì•ˆ (safe_mode: true)
4. ë‹¨ê³„ë³„ ì‹¤í–‰ ê°€ëŠ¥í•œ ëª…ë ¹ì–´ ì œê³µ
5. ë°ì´í„° ì†ì‹¤ ë°©ì§€ì— ìš°ì„ ìˆœìœ„

ìµœì‹  Kubernetesì™€ ELK Stack ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
        
        return prompt
    
    def _parse_ai_response(self, ai_response: str, error_data: Dict) -> Optional[Dict]:
        """
        AI ì‘ë‹µ íŒŒì‹±
        
        Args:
            ai_response: AI ì‘ë‹µ í…ìŠ¤íŠ¸
            error_data: ì›ë³¸ ì—ëŸ¬ ë°ì´í„°
            
        Returns:
            íŒŒì‹±ëœ ë¶„ì„ ê²°ê³¼
        """
        try:
            # JSON ë¶€ë¶„ ì¶”ì¶œ
            json_start = ai_response.find('{')
            json_end = ai_response.rfind('}') + 1
            
            if json_start == -1 or json_end == 0:
                self.logger.error("AI ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None
            
            json_str = ai_response[json_start:json_end]
            analysis_result = json.loads(json_str)
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            required_fields = ['analysis', 'solution_type', 'description', 'commands']
            for field in required_fields:
                if field not in analysis_result:
                    self.logger.error(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
                    return None
            
            # ëª…ë ¹ì–´ ì•ˆì „ì„± ê²€ì¦
            safe_commands = []
            for cmd in analysis_result['commands']:
                if self._is_safe_command(cmd):
                    safe_commands.append(cmd)
                else:
                    self.logger.warning(f"ì•ˆì „í•˜ì§€ ì•Šì€ ëª…ë ¹ì–´ ì œì™¸: {cmd.get('command', '')}")
            
            analysis_result['commands'] = safe_commands
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            analysis_result.setdefault('priority', 'medium')
            analysis_result.setdefault('estimated_time', '10')
            analysis_result.setdefault('success_probability', '70')
            
            # AutoResolverê°€ í•„ìš”ë¡œ í•˜ëŠ” ì¶”ê°€ í•„ë“œ ì„¤ì •
            analysis_result['error_data'] = error_data
            analysis_result['has_solution'] = True  # í•´ê²°ì±…ì´ ìˆìŒì„ ëª…ì‹œ
            
            self.logger.info("AI ì‘ë‹µ íŒŒì‹± ì™„ë£Œ")
            return analysis_result
            
        except json.JSONDecodeError as e:
            self.logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            self.logger.error(f"AI ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return None
    
    def _is_safe_command(self, command_info: Dict) -> bool:
        """
        ëª…ë ¹ì–´ ì•ˆì „ì„± ê²€ì¦
        
        Args:
            command_info: ëª…ë ¹ì–´ ì •ë³´
            
        Returns:
            ì•ˆì „ ì—¬ë¶€
        """
        if not self.config['resolver']['safe_mode']:
            return True
        
        command = command_info.get('command', '').lower()
        
        # ìœ„í—˜í•œ ëª…ë ¹ì–´ íŒ¨í„´
        dangerous_patterns = [
            'rm -rf', 'dd if=', 'mkfs', 'fdisk', 'format',
            'shutdown', 'reboot', 'halt', 'poweroff',
            'rm /', 'chmod 777', 'chown -R',
            'iptables -F', 'ufw --force',
            'drop database', 'truncate table', 'delete from'
        ]
        
        for pattern in dangerous_patterns:
            if pattern in command:
                return False
        
        # ì•ˆì „í•œ ëª…ë ¹ì–´ íŒ¨í„´
        safe_patterns = [
            'kubectl get', 'kubectl describe', 'kubectl logs',
            'kubectl rollout restart', 'kubectl scale',
            'curl -s', 'systemctl restart', 'systemctl status',
            'docker restart', 'helm upgrade'
        ]
        
        for pattern in safe_patterns:
            if command.startswith(pattern):
                return True
        
        # ê¸°ë³¸ì ìœ¼ë¡œ ì•ˆì „í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨
        return command_info.get('safe', False)
    
    def analyze_multiple_errors(self, errors_list: List[Dict]) -> List[Dict]:
        """
        ì—¬ëŸ¬ ì—ëŸ¬ ì¼ê´„ ë¶„ì„
        
        Args:
            errors_list: ì—ëŸ¬ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        for error_data in errors_list:
            try:
                self.logger.info(f"ì—ëŸ¬ ë¶„ì„ ì¤‘: {error_data['error_type']}")
                
                analysis_result = self.analyze_error(error_data)
                
                if analysis_result:
                    analysis_result['error_data'] = error_data
                    results.append(analysis_result)
                    self.logger.info(f"ì—ëŸ¬ ë¶„ì„ ì™„ë£Œ: {error_data['error_type']}")
                else:
                    self.logger.warning(f"ì—ëŸ¬ ë¶„ì„ ì‹¤íŒ¨: {error_data['error_type']}")
                    
            except Exception as e:
                self.logger.error(f"ì—ëŸ¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
        
        self.logger.info(f"ì´ {len(results)}ê°œ ì—ëŸ¬ ë¶„ì„ ì™„ë£Œ")
        return results
    
    def get_analysis_stats(self) -> Dict:
        """
        ë¶„ì„ í†µê³„ ì¡°íšŒ
        
        Returns:
            í†µê³„ ì •ë³´
        """
        try:
            if not self.db.connect():
                return {}
            
            # í†µê³„ ì¿¼ë¦¬ëŠ” ì—¬ê¸°ì„œ êµ¬í˜„
            # ì˜ˆ: í•´ê²°ì±… ì„±ê³µë¥ , ì—ëŸ¬ íƒ€ì…ë³„ í†µê³„ ë“±
            
            stats = {
                'total_solutions': 0,
                'avg_success_rate': 0,
                'top_error_types': []
            }
            
            return stats
            
        except Exception as e:
            self.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
        finally:
            self.db.disconnect()


# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # AI ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = AIAnalyzer()
    
    # í…ŒìŠ¤íŠ¸ ì—ëŸ¬ ë°ì´í„°
    test_error = {
        'error_type': 'kubernetes',
        'error_message': 'pod "elasticsearch-0" is in CrashLoopBackOff state',
        'source_system': 'k8s-cluster',
        'severity': 'ERROR',
        'stack_trace': 'Container failed to start: OOMKilled'
    }
    
    # ì—ëŸ¬ ë¶„ì„ í…ŒìŠ¤íŠ¸
    result = analyzer.analyze_error(test_error)
    
    if result:
        print("=== AI ë¶„ì„ ê²°ê³¼ ===")
        print(f"í•´ê²°ì±… íƒ€ì…: {result['solution_type']}")
        print(f"ì„¤ëª…: {result['description']}")
        print(f"ëª…ë ¹ì–´ ê°œìˆ˜: {len(result['commands'])}")
        for i, cmd in enumerate(result['commands'], 1):
            print(f"  {i}. {cmd['command']}")
    else:
        print("ì—ëŸ¬ ë¶„ì„ ì‹¤íŒ¨")